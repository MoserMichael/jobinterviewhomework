
## Script files

setup.sh   - set up virtual environment

start.sh    - start the test server in virtual environment

     ./start.sh -b heap - starts the test server in heap based implementation
     ./start.sh -b simple - starts the test server in simple / sort based implementation

run-test.sh - send test requests via CURL (was generated by make-test.py)

## Python files

svc.py - main test server file (listens for http requests)

CountWords.py  - class for counting frequency of words 

SimpleBackend.py - simple sort based backend implementation

HeapBackend.py  - heap based backend implementation   

Heap.py - heap that allows for deletion of element from arbitrary index (comes with unit test)

make-test.py - test generator. Generates run-test.sh

## Explanation

Two implementations are provided:

### SimpleBackend.py 
    When a new text request arrives, the input text is added into a queue. (requirement of having short times of sending text)
    
    Maintained state: a map that counts the frequency of each word, this map is updated upon computing statistics for the next batch of input.

    When statistics are requested, then a map that counts the occurance of each word is computed.
    This map is converted into a list of tuples, where the first element is the frequency of the word, the second tuple element is the word.
    The resulting list is sorted, and used to get the median value, top five elements and the lowest value.
    
    Advantage: very easy to implement
    Problem: runtime of obtaining statistics will be very slow with large set of words, due to O(nlogn) where n is the number of distinct words in the dataset. This solution does not have uniform execution time.

### HeapBackend.py

    When a new text request arrives, the input text is added into a queue. (requirement of having short times of sending text)
    
    Maintained state:  
        - for computing the minimum value: a min-heap over all entries.
        - for computing the top most frequent five elements - a min-heap with at most five elements.
        - for computing the median:
            - a min heap : includes half of upper values 
            - a max heap : includes half of the lower values
    
    When statistics is requested, then the state is updated from the next batch of available input.
    - the count of words over next batch of input is computed.
    - this count is merged into the maintained state.

    Advantage:
        - update operation is O(nlog m) where 
             - n is the number of words in the set of words queued for data update.
             - m is total number of distinct words in the data set

    Challenge:
        - need a heep that allows for deletion of arbitrary index, heapq doesn't do that.
          For this purpose the heap needs to keep track of the position of element by its key value.
        - the Heap class also keeps track of the key for each entry - this way we can delete an entry in the middle of the heap with O(log n) complexity.  


Example session:

```
# generate make-test.sh script
python make-test.py

# make test script executable
chmod +x make-test.sh

# run server in 'simple' - sorting mode (keeps running until ctrl+c)
./start.sh -b simple

# send requests to service
./run-test.sh

# run server in 'heap' mode (keeps running until ctrl+c)
./start.sh -b heap

# send requests to service
./run-test.sh
```



    
